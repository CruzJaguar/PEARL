import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import Ridge
import joblib
import numpy as np
import os
import warnings

warnings.filterwarnings('ignore')

# --- 1. Load Data ---
# NOTE: This script assumes 'train.csv' is in the same directory.
try:
    data = pd.read_csv('train.csv')
    # Drop rows with missing target value (SalePrice) for training
    data.dropna(subset=['SalePrice'], inplace=True)
except FileNotFoundError:
    print("FATAL ERROR: 'train.csv' not found. Ensure the file is in the same directory.")
    exit()

# --- 2. Define Features and Target ---
# Based on common features used in this Kaggle competition and your app.py
TARGET = 'SalePrice'
NUMERIC_FEATURES = ['LotArea', 'OverallQual', 'YearBuilt', 'GrLivArea', 'TotalBsmtSF']
CATEGORICAL_FEATURES = ['Neighborhood', 'HouseStyle'] # Example categorical features

# Ensure we only use features present in the dataset and the target is valid
features = [f for f in NUMERIC_FEATURES + CATEGORICAL_FEATURES if f in data.columns]
X = data[features]
# Apply log-transformation to the target variable, as implied by your app.py's np.expm1
y = np.log1p(data[TARGET]) 

# --- 3. Define Preprocessing Pipeline ---
# This mirrors the preprocessing step done in your notebook
numeric_transformer = Pipeline(steps=[
    ('imputer', pd.DataFrame.fillna(X, X.median(), inplace=False)), # Basic imputation
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, [f for f in NUMERIC_FEATURES if f in features]),
        ('cat', categorical_transformer, [f for f in CATEGORICAL_FEATURES if f in features])
    ],
    remainder='drop' # Drop any features not explicitly listed
)

# --- 4. Build and Train the Final Pipeline ---
# This pipeline includes preprocessing AND the optimized model (Ridge Regression)
final_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    # Using Ridge model, as implied by your project notes
    ('model', Ridge(alpha=10.0)) # Use a typical, optimized alpha value
])

print("Training the final model pipeline...")
final_pipeline.fit(X, y)
print("Model training complete.")

# --- 5. Save the Artifact ---
ARTIFACT_FILENAME = 'house_price_model.pkl'

# Save the entire pipeline (preprocessor + model)
joblib.dump(final_pipeline, ARTIFACT_FILENAME)

print(f"\nSUCCESS: The final model pipeline has been saved as '{ARTIFACT_FILENAME}'.")
print("This file must be uploaded to GitHub alongside app.py and requirements.txt.")

# --- Verification ---
# Load and test the saved model to verify it works
loaded_model = joblib.load(ARTIFACT_FILENAME)
sample_data = X.head(1)
prediction_log = loaded_model.predict(sample_data)[0]
prediction_price = np.expm1(prediction_log)

print(f"\nVerification Check:")
print(f"Sample Input: {sample_data.to_dict(orient='records')[0]}")
print(f"Predicted Price (Log): {prediction_log:.4f}")
print(f"Predicted Price (USD): ${prediction_price:,.0f}")
